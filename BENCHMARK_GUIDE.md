# ğŸ Model Benchmark Guide

## ğŸ“‹ Má»¥c Ä‘Ã­ch

So sÃ¡nh hiá»‡u nÄƒng giá»¯a:
- **Model 1**: `yolo11s.pt` (Pretrained - COCO dataset)
- **Model 2**: `yolo11s-detect.pt` (Fine-tuned - SPHAR dataset)

## ğŸš€ Quick Start

### Cháº¡y benchmark nhanh (100 frames)
```bash
cd D:\SPHAR-Dataset\scripts
python run_benchmark.py quick
```

### Cháº¡y benchmark Ä‘áº§y Ä‘á»§
```bash
python run_benchmark.py full
```

### Xem danh sÃ¡ch cáº¥u hÃ¬nh
```bash
python run_benchmark.py --list
```

## ğŸ“Š CÃ¡c cáº¥u hÃ¬nh cÃ³ sáºµn

| Config | Video | Frames | MÃ´ táº£ |
|--------|-------|--------|-------|
| **quick** | casia_angleview_p01_walk_a1.mp4 | 100 | Test nhanh (1 ngÆ°á»i) |
| **2people** | casia_angleview_p01p02_meettogether_a1.mp4 | Full | 2 ngÆ°á»i gáº·p nhau |
| **ntu** | S001C001P001R001A001_rgb.avi | Full | NTU action dataset |
| **full** | casia_angleview_p01p02_meettogether_a1.mp4 | Full | Test Ä‘áº§y Ä‘á»§ |

## ğŸ“ˆ Metrics Ä‘Æ°á»£c Ä‘o

### 1. Performance Metrics
- **Average FPS**: Frames per second
- **Inference Time**: Thá»i gian xá»­ lÃ½ má»—i frame (ms)

### 2. Detection Metrics
- **Total Detections**: Tá»•ng sá»‘ ngÆ°á»i phÃ¡t hiá»‡n
- **Avg Detections/Frame**: Trung bÃ¬nh sá»‘ ngÆ°á»i/frame
- **Detection Rate**: % frames cÃ³ phÃ¡t hiá»‡n ngÆ°á»i

### 3. Confidence Metrics
- **Average Confidence**: Äá»™ tin cáº­y trung bÃ¬nh
- **Min/Max Confidence**: Äá»™ tin cáº­y min/max

## ğŸ¯ CÃ¡ch sá»­ dá»¥ng nÃ¢ng cao

### Test vá»›i video tÃ¹y chá»‰nh
```bash
python benchmark_models.py \
    --video "path/to/video.mp4" \
    --conf 0.3 \
    --output "results.json"
```

### Test vá»›i sá»‘ frames giá»›i háº¡n
```bash
python benchmark_models.py \
    --video "video.mp4" \
    --max-frames 200 \
    --conf 0.25
```

### So sÃ¡nh 2 model tÃ¹y chá»‰nh
```bash
python benchmark_models.py \
    --model1 "model1.pt" \
    --model2 "model2.pt" \
    --video "video.mp4"
```

## ğŸ“Š Káº¿t quáº£ máº«u

```
================================================================================
ğŸ“Š BENCHMARK COMPARISON
================================================================================

Metric                         Model 1 (Pretrained)      Model 2 (Fine-tuned)      Improvement    
-----------------------------------------------------------------------------------------------
Average FPS                    28.50                     30.20                     ğŸŸ¢ +6.0%
Avg Inference Time (ms)        35.1                      33.1                      ğŸŸ¢ +5.7%
Total Detections               185                       238                       ğŸŸ¢ +28.6%
Avg Detections/Frame           0.85                      1.10                      ğŸŸ¢ +29.4%
Detection Rate (%)             78.3%                     92.6%                     ğŸŸ¢ +18.3%
Avg Confidence                 0.652                     0.743                     ğŸŸ¢ +14.0%
Min Confidence                 0.312                     0.421                     ğŸŸ¢ +34.9%
Frames w/ Detections           170                       201                       ğŸŸ¢ +18.2%
================================================================================

ğŸ“‹ SUMMARY:
   ğŸš€ Speed: Fine-tuned model is 6.0% faster
   ğŸ¯ Detection: Fine-tuned model detects 29.4% more people
   ğŸ’ª Confidence: Fine-tuned model is 14.0% more confident

ğŸ† OVERALL SCORE: +23.7%
   âœ… Fine-tuned model shows SIGNIFICANT improvement!
================================================================================
```

## ğŸ“ Output Files

### JSON Results
```json
{
  "timestamp": "2025-10-15 19:30:00",
  "model1": {
    "model_name": "Pretrained",
    "total_frames": 217,
    "total_detections": 185,
    "avg_fps": 28.50,
    ...
  },
  "model2": {
    "model_name": "Fine-tuned",
    "total_frames": 217,
    "total_detections": 238,
    "avg_fps": 30.20,
    ...
  },
  "improvements": {
    "avg_fps": 6.0,
    "avg_detections_per_frame": 29.4,
    ...
  }
}
```

LÆ°u táº¡i: `D:\SPHAR-Dataset\benchmark_<config>.json`

## ğŸ’¡ Tips

1. **Quick test trÆ°á»›c**: DÃ¹ng `quick` config Ä‘á»ƒ test nhanh
2. **Full test sau**: DÃ¹ng `full` hoáº·c `2people` cho káº¿t quáº£ chÃ­nh xÃ¡c
3. **Confidence threshold**: 
   - 0.25 (default) - balanced
   - 0.3 - fewer false positives
   - 0.2 - more detections
4. **GPU recommended**: Benchmark nhanh hÆ¡n nhiá»u vá»›i GPU

## ğŸ“ Giáº£i thÃ­ch metrics

### Detection Rate
- **>90%**: Excellent - Model phÃ¡t hiá»‡n ngÆ°á»i trong háº§u háº¿t frames
- **70-90%**: Good - Model hoáº¡t Ä‘á»™ng tá»‘t
- **<70%**: Poor - Model bá» sÃ³t nhiá»u

### Average Confidence
- **>0.7**: High confidence - Model ráº¥t cháº¯c cháº¯n
- **0.5-0.7**: Medium confidence - Model khÃ¡ tá»± tin
- **<0.5**: Low confidence - Model khÃ´ng cháº¯c cháº¯n

### Improvement Percentage
- **>20%**: Significant improvement
- **10-20%**: Good improvement
- **0-10%**: Marginal improvement
- **<0%**: No improvement (need more training)

## ğŸ› Troubleshooting

### Model not found
```bash
# Kiá»ƒm tra model paths
ls D:\SPHAR-Dataset\models\yolo11s.pt
ls D:\SPHAR-Dataset\models\finetuned\yolo11s-detect.pt
```

### Video not found
```bash
# Kiá»ƒm tra video path
python run_benchmark.py --list
```

### Out of memory
```bash
# Giáº£m sá»‘ frames
python run_benchmark.py quick  # chá»‰ 100 frames
```

## ğŸ“š Files

- `benchmark_models.py`: Main benchmark script
- `run_benchmark.py`: Quick runner vá»›i presets
- `benchmark_<config>.json`: Results output

## ğŸ‰ Example Commands

```bash
# Test nhanh
python run_benchmark.py quick

# Test Ä‘áº§y Ä‘á»§ vá»›i 2 ngÆ°á»i
python run_benchmark.py 2people

# Test vá»›i confidence cao hÆ¡n
python run_benchmark.py full --conf 0.35

# Custom benchmark
python benchmark_models.py \
    --video "my_video.mp4" \
    --max-frames 500 \
    --conf 0.3 \
    --output "my_results.json"
```

---

**Models:**
- Pretrained: `yolo11s.pt` (COCO 80 classes)
- Fine-tuned: `yolo11s-detect.pt` (SPHAR human detection)

**GPU**: NVIDIA GeForce GTX 1660 SUPER (6GB)
