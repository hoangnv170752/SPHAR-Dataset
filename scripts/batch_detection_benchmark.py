#!/usr/bin/env python3
"""
Batch Detection Benchmark Script
Ch·∫°y YOLO detection cho to√†n b·ªô dataset train ƒë·ªÉ ƒëo th·ªùi gian x·ª≠ l√Ω

Usage:
python batch_detection_benchmark.py --dataset /path/to/abnormal_detection_3class_dataset --output benchmark_results/
"""

import argparse
import json
import time
import csv
from pathlib import Path
from collections import defaultdict
import pandas as pd

from yolo_detect import YOLOHumanDetector

class DatasetDetectionBenchmark:
    def __init__(self, yolo_model="yolov8n.pt", device='cuda', conf_threshold=0.5):
        """Initialize benchmark v·ªõi YOLO detector"""
        print("Kh·ªüi t·∫°o Dataset Detection Benchmark...")
        
        self.detector = YOLOHumanDetector(
            model_path=yolo_model,
            device=device,
            conf_threshold=conf_threshold
        )
        
        self.benchmark_results = {
            'dataset_info': {},
            'video_results': {},
            'category_stats': defaultdict(lambda: {
                'total_videos': 0,
                'total_time': 0,
                'avg_time_per_video': 0,
                'total_detections': 0,
                'avg_detections_per_video': 0
            }),
            'overall_stats': {}
        }
        
    def process_dataset(self, dataset_path, output_dir, splits=['train'], save_detection_results=False, sample_size=None):
        """
        X·ª≠ l√Ω to√†n b·ªô dataset v√† ƒëo benchmark
        
        Args:
            dataset_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn dataset (abnormal_detection_3class_dataset)
            output_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ benchmark
            splits: Danh s√°ch splits c·∫ßn x·ª≠ l√Ω ['train', 'val', 'test']
            save_detection_results: C√≥ l∆∞u k·∫øt qu·∫£ detection kh√¥ng
            sample_size: S·ªë l∆∞·ª£ng videos random ƒë·ªÉ benchmark (None = t·∫•t c·∫£)
        """
        dataset_path = Path(dataset_path)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"B·∫Øt ƒë·∫ßu benchmark dataset: {dataset_path}")
        print(f"K·∫øt qu·∫£ s·∫Ω l∆∞u t·∫°i: {output_dir}")
        if sample_size:
            print(f"üé≤ Ch·∫ø ƒë·ªô sampling: {sample_size} videos ng·∫´u nhi√™n")
        
        # Collect t·∫•t c·∫£ video files tr∆∞·ªõc
        all_video_files = []
        dataset_structure = {}
        
        for split in splits:
            split_path = dataset_path / 'videos' / split
            if split_path.exists():
                dataset_structure[split] = {}
                for category_dir in split_path.iterdir():
                    if category_dir.is_dir():
                        category_name = category_dir.name
                        video_files = list(category_dir.glob('*.mp4')) + list(category_dir.glob('*.avi'))
                        dataset_structure[split][category_name] = len(video_files)
                        
                        # Th√™m v√†o danh s√°ch t·ªïng v·ªõi metadata
                        for video_file in video_files:
                            all_video_files.append({
                                'path': video_file,
                                'split': split,
                                'category': category_name
                            })
        
        total_videos_count = len(all_video_files)
        
        # Random sampling n·∫øu c·∫ßn
        if sample_size and sample_size < total_videos_count:
            import random
            random.seed(42)  # ƒê·ªÉ k·∫øt qu·∫£ reproducible
            sampled_videos = random.sample(all_video_files, sample_size)
            print(f"üéØ ƒê√£ ch·ªçn {sample_size} videos t·ª´ {total_videos_count} videos")
        else:
            sampled_videos = all_video_files
            print(f"üéØ X·ª≠ l√Ω t·∫•t c·∫£ {total_videos_count} videos")
        
        print(f"\nüìä T·ªîNG QUAN DATASET:")
        print(f"{'='*50}")
        for split, categories in dataset_structure.items():
            split_total = sum(categories.values())
            print(f"üìÅ {split.upper()}: {split_total} videos")
            for category, count in categories.items():
                print(f"   ‚îî‚îÄ‚îÄ {category}: {count} videos")
        print(f"üéØ T·ªîNG C·ªòNG: {total_videos_count} videos")
        print(f"‚è∞ ∆Ø·ªõc t√≠nh th·ªùi gian: ~{total_videos_count * 0.5 / 3600:.1f}h (0.5s/video)")
        print(f"{'='*50}\n")
        
        # L∆∞u th√¥ng tin dataset
        self.benchmark_results['dataset_info'] = {
            'dataset_path': str(dataset_path),
            'splits_processed': splits,
            'total_videos': total_videos_count,
            'sampled_videos': len(sampled_videos),
            'sample_size': sample_size,
            'dataset_structure': dataset_structure,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        total_videos_processed = 0
        total_processing_time = 0
        
        print(f"\nüöÄ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù {len(sampled_videos)} VIDEOS")
        print(f"{'='*60}")
        
        # Group sampled videos by category for stats
        category_stats = defaultdict(lambda: {'total_time': 0, 'total_detections': 0, 'count': 0})
        
        # X·ª≠ l√Ω t·ª´ng video ƒë√£ ƒë∆∞·ª£c sample
        for i, video_info in enumerate(sampled_videos, 1):
            video_start_time = time.time()
            
            print(f"\n{'='*60}")
            print(f"üìπ [{video_info['split']}] [{video_info['category']}] Video {i}/{len(sampled_videos)}")
            print(f"üìÅ File: {video_info['path'].name}")
            print(f"‚è∞ Th·ªùi gian: {time.strftime('%H:%M:%S')}")
            print(f"{'='*60}")
            
            # T·∫°o output directory cho video n√†y n·∫øu c·∫ßn
            video_output_dir = None
            if save_detection_results:
                video_output_dir = output_dir / 'detection_results' / video_info['split'] / video_info['category'] / video_info['path'].stem
            
            # Ch·∫°y detection
            detection_results = self.detector.process_video(
                video_path=video_info['path'],
                output_dir=video_output_dir,
                save_frames=False,
                visualize=False
            )
            
            processing_time = time.time() - video_start_time
            
            if detection_results:
                total_detections = detection_results['processing_stats']['total_detections']
                fps_achieved = detection_results['processing_stats']['fps_achieved']
                total_frames = detection_results['video_info']['total_frames']
                
                # L∆∞u k·∫øt qu·∫£ cho video n√†y
                video_key = f"{video_info['split']}_{video_info['category']}_{video_info['path'].stem}"
                self.benchmark_results['video_results'][video_key] = {
                    'video_path': str(video_info['path']),
                    'split': video_info['split'],
                    'category': video_info['category'],
                    'processing_time': processing_time,
                    'total_frames': total_frames,
                    'total_detections': total_detections,
                    'fps_achieved': fps_achieved,
                    'avg_detections_per_frame': total_detections / total_frames if total_frames > 0 else 0
                }
                
                category_key = f"{video_info['split']}_{video_info['category']}"
                category_stats[category_key]['total_time'] += processing_time
                category_stats[category_key]['total_detections'] += total_detections
                category_stats[category_key]['count'] += 1
                
                total_videos_processed += 1
                total_processing_time += processing_time
                
                # Progress info v·ªõi th·ªùi gian ∆∞·ªõc t√≠nh
                remaining_videos = len(sampled_videos) - i
                avg_time_per_video = total_processing_time / i
                estimated_remaining_time = remaining_videos * avg_time_per_video
                
                print(f"‚úÖ HO√ÄN TH√ÄNH trong {processing_time:.2f}s")
                print(f"üìä Detections: {total_detections} | FPS: {fps_achieved:.1f}")
                print(f"‚è±Ô∏è  C√≤n l·∫°i: {remaining_videos} videos (~{estimated_remaining_time/60:.1f} ph√∫t)")
                print(f"üìà Ti·∫øn ƒë·ªô: {i}/{len(sampled_videos)} ({i/len(sampled_videos)*100:.1f}%)")
                
            else:
                print(f"‚ùå L·ªñI x·ª≠ l√Ω video: {video_info['path'].name}")
        
        # T·∫°o category stats t·ª´ sampled data
        for category_key, stats in category_stats.items():
            if stats['count'] > 0:
                self.benchmark_results['category_stats'][category_key] = {
                    'split': category_key.split('_')[0],
                    'category': '_'.join(category_key.split('_')[1:]),
                    'total_videos': stats['count'],
                    'total_time': stats['total_time'],
                    'avg_time_per_video': stats['total_time'] / stats['count'],
                    'total_detections': stats['total_detections'],
                    'avg_detections_per_video': stats['total_detections'] / stats['count']
                }
        
        # T√≠nh to√°n overall stats
        self.benchmark_results['overall_stats'] = {
            'total_videos_processed': total_videos_processed,
            'total_processing_time': total_processing_time,
            'avg_time_per_video': total_processing_time / total_videos_processed if total_videos_processed > 0 else 0,
            'videos_per_hour': 3600 / (total_processing_time / total_videos_processed) if total_videos_processed > 0 else 0
        }
        
        # L∆∞u k·∫øt qu·∫£
        self.save_benchmark_results(output_dir)
        
        # In summary
        self.print_benchmark_summary()
        
        return self.benchmark_results
    
    def save_benchmark_results(self, output_dir):
        """L∆∞u k·∫øt qu·∫£ benchmark"""
        output_dir = Path(output_dir)
        
        # L∆∞u JSON ƒë·∫ßy ƒë·ªß
        json_path = output_dir / 'benchmark_results.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self.benchmark_results, f, indent=2, ensure_ascii=False)
        print(f"K·∫øt qu·∫£ JSON l∆∞u t·∫°i: {json_path}")
        
        # L∆∞u CSV cho video results
        video_csv_path = output_dir / 'video_benchmark.csv'
        video_data = []
        for video_key, video_info in self.benchmark_results['video_results'].items():
            video_data.append(video_info)
        
        if video_data:
            df_videos = pd.DataFrame(video_data)
            df_videos.to_csv(video_csv_path, index=False, encoding='utf-8')
            print(f"Video benchmark CSV l∆∞u t·∫°i: {video_csv_path}")
        
        # L∆∞u CSV cho category stats
        category_csv_path = output_dir / 'category_benchmark.csv'
        category_data = []
        for category_key, category_info in self.benchmark_results['category_stats'].items():
            category_data.append(category_info)
        
        if category_data:
            df_categories = pd.DataFrame(category_data)
            df_categories.to_csv(category_csv_path, index=False, encoding='utf-8')
            print(f"Category benchmark CSV l∆∞u t·∫°i: {category_csv_path}")
    
    def print_benchmark_summary(self):
        """In t√≥m t·∫Øt k·∫øt qu·∫£ benchmark"""
        stats = self.benchmark_results['overall_stats']
        
        print(f"\n{'='*80}")
        print(f"T√ìM T·∫ÆT K·∫æT QU·∫¢ BENCHMARK")
        print(f"{'='*80}")
        print(f"T·ªïng s·ªë videos x·ª≠ l√Ω: {stats['total_videos_processed']}")
        print(f"T·ªïng th·ªùi gian x·ª≠ l√Ω: {stats['total_processing_time']:.2f} gi√¢y ({stats['total_processing_time']/3600:.2f} gi·ªù)")
        print(f"Th·ªùi gian trung b√¨nh/video: {stats['avg_time_per_video']:.2f} gi√¢y")
        print(f"T·ªëc ƒë·ªô x·ª≠ l√Ω: {stats['videos_per_hour']:.1f} videos/gi·ªù")
        
        print(f"\nK·∫æT QU·∫¢ THEO CATEGORY:")
        print(f"{'Category':<30} {'Videos':<8} {'T·ªïng th·ªùi gian':<15} {'TB/video':<12} {'TB detections':<15}")
        print(f"{'-'*80}")
        
        for category_key, category_stats in self.benchmark_results['category_stats'].items():
            print(f"{category_key:<30} {category_stats['total_videos']:<8} "
                  f"{category_stats['total_time']:<15.2f} {category_stats['avg_time_per_video']:<12.2f} "
                  f"{category_stats['avg_detections_per_video']:<15.1f}")

def main():
    parser = argparse.ArgumentParser(description='Dataset Detection Benchmark')
    parser.add_argument('--dataset', '-d', required=True, 
                       help='ƒê∆∞·ªùng d·∫´n ƒë·∫øn dataset (abnormal_detection_3class_dataset)')
    parser.add_argument('--output', '-o', required=True, 
                       help='Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ benchmark')
    parser.add_argument('--splits', nargs='+', default=['train'], 
                       help='Danh s√°ch splits c·∫ßn x·ª≠ l√Ω (default: train)')
    parser.add_argument('--model', '-m', default='yolov8n.pt', 
                       help='YOLO model path')
    parser.add_argument('--conf', '-c', type=float, default=0.5, 
                       help='Confidence threshold')
    parser.add_argument('--device', default='cuda', 
                       help='Device (cuda/cpu)')
    parser.add_argument('--save-detections', action='store_true',
                       help='L∆∞u k·∫øt qu·∫£ detection cho t·ª´ng video')
    parser.add_argument('--sample-size', type=int, default=None,
                       help='S·ªë l∆∞·ª£ng videos random ƒë·ªÉ benchmark (None = t·∫•t c·∫£)')
    
    args = parser.parse_args()
    
    # Ki·ªÉm tra dataset path
    dataset_path = Path(args.dataset)
    if not dataset_path.exists():
        print(f"L·ªói: Kh√¥ng t√¨m th·∫•y dataset t·∫°i {dataset_path}")
        return
    
    # Kh·ªüi t·∫°o benchmark
    benchmark = DatasetDetectionBenchmark(
        yolo_model=args.model,
        device=args.device,
        conf_threshold=args.conf
    )
    
    # Ch·∫°y benchmark
    results = benchmark.process_dataset(
        dataset_path=args.dataset,
        output_dir=args.output,
        splits=args.splits,
        save_detection_results=args.save_detections,
        sample_size=args.sample_size
    )
    
    print(f"\nBenchmark ho√†n th√†nh! K·∫øt qu·∫£ l∆∞u t·∫°i: {args.output}")

if __name__ == "__main__":
    main()
