# üèÜ Multi-Model Benchmark Guide

## üìã Overview

So s√°nh **3 models** tr√™n **5 videos** test:

### ü§ñ Models
1. **YOLOv8s** - YOLOv8 small (pretrained COCO)
2. **YOLOv11s** - YOLOv11 small (pretrained COCO)
3. **YOLOv11s-FT** - YOLOv11 small fine-tuned tr√™n SPHAR dataset

### üìπ Test Videos
1. **1person_walk** - 1 ng∆∞·ªùi ƒëi b·ªô
2. **2people_meet** - 2 ng∆∞·ªùi g·∫∑p nhau
3. **2people_follow** - 2 ng∆∞·ªùi theo nhau
4. **2people_overtake** - 2 ng∆∞·ªùi v∆∞·ª£t nhau
5. **ntu_action** - NTU action dataset

## üöÄ Quick Start

### Ch·∫°y benchmark ƒë·∫ßy ƒë·ªß
```bash
cd D:\SPHAR-Dataset\scripts
python run_benchmark.py multi
```

### Ch·∫°y nhanh (100 frames/video)
```bash
python run_benchmark.py multi --max-frames 100
```

### V·ªõi confidence threshold kh√°c
```bash
python run_benchmark.py multi --conf 0.35
```

### Ho·∫∑c ch·∫°y tr·ª±c ti·∫øp
```bash
python benchmark_multi_models.py --conf 0.25
```

## üìä Output Format

### 1. Comparison Tables

```
üìà Average FPS
--------------------------------------------------------------------------------
              YOLOv8s  YOLOv11s  YOLOv11s-FT
1person_walk     28.5      29.2         30.8
2people_meet     27.3      28.1         29.5
2people_follow   26.8      27.9         29.2
...

üìà Detections/Frame
--------------------------------------------------------------------------------
              YOLOv8s  YOLOv11s  YOLOv11s-FT
1person_walk     0.95      0.92         1.05
2people_meet     1.85      1.78         2.12
...
```

### 2. Overall Performance

```
üèÜ OVERALL MODEL PERFORMANCE
--------------------------------------------------------------------------------
              avg_fps  avg_detections_per_frame  detection_rate  avg_confidence
YOLOv8s          27.5                      1.25            82.3           0.658
YOLOv11s         28.3                      1.18            79.8           0.671
YOLOv11s-FT      29.8                      1.42            89.5           0.745
```

### 3. Composite Scores

```
üéØ COMPOSITE SCORES (0-100)
--------------------------------------------------------------------------------
ü•á YOLOv11s-FT      : 100.0
ü•à YOLOv8s          : 67.3
ü•â YOLOv11s         : 58.9
```

## üìà Metrics Explained

### Performance Metrics
- **avg_fps**: T·ªëc ƒë·ªô x·ª≠ l√Ω (frames/second)
- **avg_inference_time_ms**: Th·ªùi gian inference (milliseconds)

### Detection Metrics
- **avg_detections_per_frame**: S·ªë ng∆∞·ªùi ph√°t hi·ªán trung b√¨nh/frame
- **detection_rate**: % frames c√≥ ph√°t hi·ªán ng∆∞·ªùi
- **total_detections**: T·ªïng s·ªë detections

### Quality Metrics
- **avg_confidence**: ƒê·ªô tin c·∫≠y trung b√¨nh
- **min/max_confidence**: ƒê·ªô tin c·∫≠y min/max

### Composite Score
ƒêi·ªÉm t·ªïng h·ª£p (0-100) ƒë∆∞·ª£c t√≠nh t·ª´:
- Speed (20%): FPS
- Detection (30%): Detections per frame
- Coverage (30%): Detection rate
- Quality (20%): Confidence

## üìÅ Output Files

### JSON Result
L∆∞u t·∫°i: `D:\SPHAR-Dataset\multi_model_benchmark.json`

```json
{
  "timestamp": "2025-10-15 19:30:00",
  "device": "cuda",
  "models": ["YOLOv8s", "YOLOv11s", "YOLOv11s-FT"],
  "results": [
    {
      "model_name": "YOLOv11s-FT",
      "video_id": "2people_meet",
      "total_frames": 217,
      "avg_fps": 29.5,
      "avg_detections_per_frame": 2.12,
      "detection_rate": 94.3,
      "avg_confidence": 0.745
    },
    ...
  ]
}
```

## üéØ Use Cases

### 1. Ch·ªçn model t·ªët nh·∫•t
```bash
python run_benchmark.py multi
# Xem composite scores ƒë·ªÉ ch·ªçn model
```

### 2. So s√°nh speed vs accuracy
```bash
# Lower confidence = more detections but slower
python run_benchmark.py multi --conf 0.2

# Higher confidence = fewer detections but faster
python run_benchmark.py multi --conf 0.4
```

### 3. Quick test tr√™n subset
```bash
python run_benchmark.py multi --max-frames 50
```

## üí° Tips

1. **Full benchmark**: Ch·∫°y kh√¥ng gi·ªõi h·∫°n frames ƒë·ªÉ k·∫øt qu·∫£ ch√≠nh x√°c nh·∫•t
2. **Quick test**: D√πng `--max-frames 100` ƒë·ªÉ test nhanh
3. **Confidence**: 0.25-0.35 l√† kho·∫£ng t·ªët cho most cases
4. **GPU required**: Benchmark s·∫Ω r·∫•t ch·∫≠m tr√™n CPU

## üìä Expected Results

Based on initial tests:

| Model | Speed | Detection | Quality | Overall |
|-------|-------|-----------|---------|---------|
| YOLOv8s | üü° Medium | üü¢ Good | üü¢ Good | üü¢ Good |
| YOLOv11s | üü¢ Fast | üü° Medium | üü¢ Good | üü° Medium |
| YOLOv11s-FT | üü¢ Fast | üü¢ Excellent | üü¢ Excellent | ü•á Best |

**Winner**: YOLOv11s-FT (fine-tuned) should win overall

## üÜò Troubleshooting

### Missing model
```bash
# Check models exist
ls D:\SPHAR-Dataset\models\yolov8s.pt
ls D:\SPHAR-Dataset\models\yolo11s.pt
ls D:\SPHAR-Dataset\models\finetuned\yolo11s-detect.pt
```

### pandas not found
```bash
pip install pandas tqdm
# Or install all requirements
pip install -r requirements_tracking.txt
```

### Out of memory
```bash
# Use fewer frames
python run_benchmark.py multi --max-frames 100
```

### Video not found
Check that videos exist:
```bash
ls D:\SPHAR-Dataset\videos\walking\*.mp4
ls D:\SPHAR-Dataset\videos\NTU\A001\*.avi
```

## üéì Understanding Results

### High composite score (>80)
‚úÖ Model performs well across all metrics

### Medium score (50-80)
‚ö†Ô∏è Model good in some areas, needs improvement in others

### Low score (<50)
‚ùå Model needs significant improvement or more training

### Fine-tuned advantage
Fine-tuned model should show:
- ‚úÖ Higher detection rate (better recall)
- ‚úÖ Higher confidence (more certain)
- ‚úÖ More detections per frame (fewer misses)
- ‚ö†Ô∏è Similar or slightly better speed

## üìö Files

- `benchmark_multi_models.py`: Main benchmark script
- `run_benchmark.py`: Quick runner with multi support
- `multi_model_benchmark.json`: Output results

## üéâ Example Commands

```bash
# Full benchmark (recommended)
python run_benchmark.py multi

# Quick test
python run_benchmark.py multi --max-frames 100

# High confidence
python run_benchmark.py multi --conf 0.35

# Low confidence (more detections)
python run_benchmark.py multi --conf 0.2

# See available configs
python run_benchmark.py --list
```

---

**Models Tested:**
- YOLOv8s (pretrained)
- YOLOv11s (pretrained)
- YOLOv11s-FT (fine-tuned on SPHAR)

**Test Dataset**: 5 videos from SPHAR-Dataset  
**GPU**: NVIDIA GeForce GTX 1660 SUPER (6GB)
